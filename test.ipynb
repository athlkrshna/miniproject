{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPonhibvkYqT45TRYqdehm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnav-197/miniproject/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kUDNnTYMU6P"
      },
      "source": [
        "\n",
        "import cv2\n",
        "import numpy\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Yv1gqHM94r"
      },
      "source": [
        "json_file = open('model_final.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_final.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-kAsfa7QNjm"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ISGu_SL__Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "815a4da0-84b5-4f0a-c784-483ba1059e46"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "img = cv2.imread('/content/test.jpg',cv2.IMREAD_GRAYSCALE)\n",
        "#kernel = np.ones((3,3),np.uint8)\n",
        "cv2_imshow(img)\n",
        "#erosion = cv2.erode(img,kernel,iterations = 3)\n",
        "#dilation = cv2.dilate(img,kernel,iterations = 1)\n",
        "#img=dilation\n",
        "if img is not None:\n",
        "    #images.append(img)\n",
        "    img=~img\n",
        "    ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
        "    ctrs,ret=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "    w=int(28)\n",
        "    h=int(28)\n",
        "    train_data=[]\n",
        "    #print(len(cnt))\n",
        "    rects=[]\n",
        "    for c in cnt :\n",
        "        x,y,w,h= cv2.boundingRect(c)\n",
        "        rect=[x,y,w,h]\n",
        "        rects.append(rect)\n",
        "    #print(rects)\n",
        "    bool_rect=[]\n",
        "    for r in rects:\n",
        "        l=[]\n",
        "        for rec in rects:\n",
        "            flag=0\n",
        "            if rec!=r:\n",
        "                if r[0]<(rec[0]+rec[2]+10) and rec[0]<(r[0]+r[2]+10) and r[1]<(rec[1]+rec[3]+10) and rec[1]<(r[1]+r[3]+10):\n",
        "                    flag=1\n",
        "                l.append(flag)\n",
        "            if rec==r:\n",
        "                l.append(0)\n",
        "        bool_rect.append(l)\n",
        "    #print(bool_rect)\n",
        "    dump_rect=[]\n",
        "    for i in range(0,len(cnt)):\n",
        "        for j in range(0,len(cnt)):\n",
        "            if bool_rect[i][j]==1:\n",
        "                area1=rects[i][2]*rects[i][3]\n",
        "                area2=rects[j][2]*rects[j][3]\n",
        "                if(area1==min(area1,area2)):\n",
        "                    dump_rect.append(rects[i])\n",
        "    #print(len(dump_rect)) \n",
        "    final_rect=[i for i in rects if i not in dump_rect]\n",
        "    #print(final_rect)\n",
        "    for r in final_rect:\n",
        "        x=r[0]\n",
        "        y=r[1]\n",
        "        w=r[2]\n",
        "        h=r[3]\n",
        "        im_crop =thresh[y:y+h+10,x:x+w+10]\n",
        "        \n",
        "\n",
        "        im_resize = cv2.resize(im_crop,(28,28))\n",
        "        cv2_imshow(im_resize)\n",
        "        \n",
        "\n",
        "        im_resize=np.reshape(im_resize,(1,28,28))\n",
        "        train_data.append(im_resize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1000x600 at 0x7FAEAC163650>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAo0lEQVR4nLWSvQ3CUAyEzyBKKiQoaGAOZqCiyAyZhSFYhBIaWIKaiIYKoUgfRRLl59mIhqv8/OnOkv0kSRcaPdQTA2UJPNWPF7BTqAJWMX3DoaktobTNUQJNIoRaxzMlwSx0Spp+g/HMv8N0Q50Vuc5lmLWHkAm2AclzeProCASh1R+6OWQBQHHtNU1SOfaCyolM7eEHsmoXm07rPq+Ls2/5TR+GrVH94cxXsAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FAEAC163650>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMgq53_Lq3j9",
        "outputId": "6abd6a13-62de-4989-91bf-e0bc593d2508"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "Awi7Dqcsq5f2",
        "outputId": "1f60b1b1-da68-4681-b466-f73374818bc9"
      },
      "source": [
        "s=''\n",
        "for i in range(len(train_data)):\n",
        "    train_data[i]=np.array(train_data[i])\n",
        "    train_data[i]=train_data[i].reshape(1,1,28,28)\n",
        "    print(train_data[i].shape)\n",
        "    result=loaded_model.predict_classes(train_data[i])\n",
        "    if(result[0]==10):\n",
        "        s=s+'-'\n",
        "    if(result[0]==11):\n",
        "        s=s+'+'\n",
        "    if(result[0]==12):\n",
        "        s=s+'*'\n",
        "    if(result[0]==0):\n",
        "        s=s+'0'\n",
        "    if(result[0]==1):\n",
        "        s=s+'1'\n",
        "    if(result[0]==2):\n",
        "        s=s+'2'\n",
        "    if(result[0]==3):\n",
        "        s=s+'3'\n",
        "    if(result[0]==4):\n",
        "        s=s+'4'\n",
        "    if(result[0]==5):\n",
        "        s=s+'5'\n",
        "    if(result[0]==6):\n",
        "        s=s+'6'\n",
        "    if(result[0]==7):\n",
        "        s=s+'7'\n",
        "    if(result[0]==8):\n",
        "        s=s+'8'\n",
        "    if(result[0]==9):\n",
        "        s=s+'9'\n",
        "    if(result[0]==13):\n",
        "        s=s+'('\n",
        "    if(result[0]==14):\n",
        "        s=s+')'\n",
        "    \n",
        "print(s)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f4c90cdeb76e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    457\u001b[0m                   \u001b[0;34m'  if your model does binary classification '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                   '  (e.g. if it uses a `sigmoid` last-layer activation).')\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 895\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential_2/max_pooling2d_3/MaxPool (defined at <ipython-input-6-f4c90cdeb76e>:6) ]] [Op:__inference_predict_function_253]\n\nFunction call stack:\npredict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaHkWOpgq7yl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}